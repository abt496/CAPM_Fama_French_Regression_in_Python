{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1789b6e6-a785-49fa-b042-0e8417ca27b4",
   "metadata": {},
   "source": [
    "# Capital Asset Pricing Model & Fama-French 3-Factor Regression in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0772d80a-f367-47b2-8f3e-9e47728dfa36",
   "metadata": {},
   "source": [
    "The following code performs several financial analyses, mainly focusing on regression models and descriptive statistics for ETF and mutual fund data. \n",
    "\n",
    "First, it loads the relevant sheets from Excel files and prepares the data by calculating log returns and aligning with a risk-free rate. The code then conducts CAPM and Fama-French 3-Factor regressions, generating outputs such as coefficients, p-values, and R-squared values etc. \n",
    "Additionally, it performs diagnostic tests (e.g., Durbin-Watson, Breusch-Pagan, White test) and calculates descriptive statistics. Finally, visualizations of residuals and fitted values are created to assess model assumptions and results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64912f7b-4765-48bd-ac88-911b94e837bf",
   "metadata": {},
   "source": [
    "### Models used in this analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888230ae-ec21-468c-9859-1ab33de82884",
   "metadata": {},
   "source": [
    "#### • Capital Asset Pricing Model (CAPM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c3d1d7-f81f-4ac4-b927-451e464c6617",
   "metadata": {},
   "source": [
    "#### $$ln⁡Δ R_p-ln⁡Δ R_f=α_i+β_1 ⋅ {ln⁡Δ R_m-ln⁡Δ R_f }+ϵ_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63333fea-01f2-47b0-9a50-9d45ef309646",
   "metadata": {},
   "source": [
    "| Expression | Description |\n",
    "|------------|-------------|\n",
    "| $$ \\ln \\Delta R_p - \\ln \\Delta R_f $$ | The natural logarithm of the excess return of the fund. |\n",
    "| $$ \\alpha_i $$ | The alpha value of the portfolio. |\n",
    "| $$ \\beta_1 $$ | The beta coefficient of the portfolio. |\n",
    "| $$ \\ln \\Delta R_m - \\ln \\Delta R_f $$  | The natural logarithm of the change in return of the market portfolio. |\n",
    "| $$ \\epsilon_i $$ | The residual value for the portfolio, that cannot be explained by market movements. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6a5159-273b-47e8-bb17-95ef8b8e7d82",
   "metadata": {},
   "source": [
    "#### • Fama-French 3 Factor Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff86233-32fa-4234-a3e7-0fb8e04ab5a1",
   "metadata": {},
   "source": [
    "#### $$ ln⁡Δ R_p-ln⁡Δ R_f=α_i+β_1 ⋅ {ln⁡Δ R_m-ln⁡Δ R_f }+β_2 ⋅ {SMB} + β_3 ⋅ {HML}+ϵ_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4177c7d3-8f0b-4027-aefb-545404942282",
   "metadata": {},
   "source": [
    "| Expression | Description |\n",
    "|------------|-------------|\n",
    "| $$ \\ln \\Delta R_p - \\ln \\Delta R_f $$ | The natural logarithm of the excess return of the fund. |\n",
    "| $$ \\alpha_i $$ | The alpha value of the portfolio. |\n",
    "| $$ \\beta_1 $$ | The beta coefficient of the portfolio. |\n",
    "| $$ \\ln \\Delta R_m - \\ln \\Delta R_f $$  | The natural logarithm of the change in return of the market portfolio. |\n",
    "| $$ \\beta_2 \\, ⋅ \\text{SMB} $$ | The Small Minus Big factor, which explains the return difference between small and large companies. |\n",
    "| $$ \\beta_3 \\,⋅  \\text{HML} $$ | The High Minus Low factor, which explains the return difference between portfolios with high and low book-to-market ratios. |\n",
    "| $$ \\epsilon_i $$ | The residual value for the portfolio that cannot be explained by market movements.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628465bf-16ad-49ed-9845-f3d1b74c4b61",
   "metadata": {},
   "source": [
    "### The first step is to load the excel-files containing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "b8e1d89b-1b9b-42c1-966f-2254386338ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_file_path_excel = r'C:\\Users\\...\\Data_ETF.xlsm'\n",
    "mutual_file_path_excel = r'C:\\Users\\...\\Data_Mutual.xlsm'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfb57ff-1a90-4d69-9c93-364de3f7ce88",
   "metadata": {},
   "source": [
    "#### Importing all relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "9c6f2469-f937-4fef-bf8a-4252d551f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "import glob\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.drawing.image import Image\n",
    "import warnings\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "from scipy.stats import skew, kurtosis, jarque_bera\n",
    "from openpyxl import load_workbook\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan, het_white\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.stats.stattools import jarque_bera\n",
    "from statsmodels.stats.api import het_breuschpagan\n",
    "import statsmodels.stats.api as smd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1eee65-e9bc-437f-820e-e604ad364240",
   "metadata": {},
   "source": [
    "#### Loading the excel files and relevant sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95daa86a-f0da-491b-bc25-8bc247e3de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_closing_mutual = pd.read_excel(mutual_file_path_excel, sheet_name='Closing_Prices').iloc[:73]\n",
    "df_closing_etf = pd.read_excel(etf_file_path_excel, sheet_name='Closing_Prices', skiprows=1).iloc[:73]\n",
    "df_data_capm_fama = pd.read_excel(etf_file_path_excel, sheet_name='Data_CAPM_FAMA', skiprows=11).iloc[:72]\n",
    "df_riskfree = df_data_capm_fama[['Dates', 'ln riskfree']].iloc[:72]\n",
    "df_regressor_capm = df_data_capm_fama[['Dates', 'ln excess']].iloc[:72]\n",
    "df_regressor_capm.set_index('Dates', inplace=True)\n",
    "df_regressor_fama = df_data_capm_fama[['Dates', 'ln excess', 'SMB', 'HML']].iloc[:72]\n",
    "df_regressor_fama.set_index('Dates', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efce02f6-a203-4b89-8b63-6d3ddad8e387",
   "metadata": {},
   "source": [
    "### Overview of Function-based code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18464dd0-468e-4126-9b58-4225a1d45811",
   "metadata": {},
   "source": [
    "#### Calculating Log returns and replacing of missing values with the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a80f6d6-1795-4be1-9b55-ed06f1d0f3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_returns(df):\n",
    "    '''\n",
    "    Calculates the ln return \n",
    "    '''\n",
    "    date_column = df.iloc[:, 0]\n",
    "    log_returns = np.log(df.iloc[:, 1:].shift(1) / df.iloc[:, 1:])\n",
    "    log_returns.insert(0, 'Date', date_column)\n",
    "    return log_returns\n",
    "\n",
    "def replace_nans_and_zeros_with_mean(series):\n",
    "    '''\n",
    "    Replaces NaN and 0 values between the first and last valid value with the mean value of the entire time series.\n",
    "    '''\n",
    "    # Calculate the mean value of the valid values (without NaN and 0 values)\n",
    "    valid_values = series[(series != 0) & series.notna()]\n",
    "    overall_mean = valid_values.mean()\n",
    "    if valid_values.empty:\n",
    "        # If there are no valid values, the unchanged series is returned\n",
    "        return series\n",
    "    # Indices of valid values\n",
    "    valid_indices = valid_values.index\n",
    "    # Determining the first and last valid index\n",
    "    first_valid_index = valid_indices.min()  # newest values \n",
    "    last_valid_index = valid_indices.max()   # oldest values\n",
    "    # Mask for values between the first and last valid value that are NaN or 0\n",
    "    mask = ((series == 0) | series.isna()) & (series.index >= first_valid_index) & (series.index <= last_valid_index)\n",
    "    # Replacing these values with the mean value\n",
    "    series.loc[mask] = overall_mean\n",
    "    return series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757a4840-fb64-44fe-803e-97075312dfa1",
   "metadata": {},
   "source": [
    "#### CAPM & Fama-French Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b973d67-d43f-439e-a026-6b9dfd30c935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_capm(log_excess_return, df_regressor_capm, writer):\n",
    "    '''\n",
    "    Performs the CAPM regression and stores the resulting data, residuals, and fitted values in data frames.\n",
    "    '''\n",
    "    results_list = []\n",
    "    residuals_dict = {}\n",
    "    fitted_values_dict = {}\n",
    "    \n",
    "    # Only numeric regressor column\n",
    "    X = df_regressor_capm['ln excess'].astype(float)  # Convert to float if necessary\n",
    "    \n",
    "    # Loop through the columns of log_excess_return\n",
    "    for column in log_excess_return.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        y = log_excess_return[column].astype(float)  # Convert to float if necessary\n",
    "        # Combine dependent variable and regressor, removing NaN rows and performing regression\n",
    "        regression_data = pd.concat([y, X], axis=1).dropna()\n",
    "        y_clean = regression_data.iloc[:, 0]\n",
    "        X_clean = sm.add_constant(regression_data.iloc[:, 1])\n",
    "        model = sm.OLS(y_clean, X_clean)\n",
    "        results = model.fit()     \n",
    "        # Temporarily saving regression results\n",
    "        result_dict = {\n",
    "            'Fund': column,\n",
    "            'Alpha': results.params[0],\n",
    "            'Beta': results.params[1],\n",
    "            'P-Values Alpha': results.pvalues[0],\n",
    "            'P-Values Beta': results.pvalues[1],\n",
    "            'R-Squared': results.rsquared,\n",
    "            'Confidence Interval Alpha': results.conf_int().iloc[0].tolist(),\n",
    "            'Confidence Interval Beta': results.conf_int().iloc[1].tolist()\n",
    "        }\n",
    "        results_list.append(result_dict)\n",
    "        # Temporarily saving residuals and fitted values\n",
    "        residuals_dict[column] = pd.Series(results.resid).reindex(log_excess_return.index).tolist()\n",
    "        fitted_values_dict[column] = pd.Series(results.fittedvalues).reindex(log_excess_return.index).tolist()\n",
    "\n",
    "    # Converting results, residuals, and fitted values to dataframes\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    residuals_df = pd.DataFrame(residuals_dict, index=log_excess_return.index)\n",
    "    fitted_values_df = pd.DataFrame(fitted_values_dict, index=log_excess_return.index)\n",
    "    # Saving to Excel\n",
    "    results_df.to_excel(writer, sheet_name='CAPM Results', index=False)\n",
    "    residuals_df.to_excel(writer, sheet_name='Residuals', index=True)\n",
    "    fitted_values_df.to_excel(writer, sheet_name='Fitted Values', index=True)\n",
    "    return results_df, residuals_df, fitted_values_df\n",
    "\n",
    "def regression_fama(log_excess_return, df_regressor_fama, writer):\n",
    "    '''\n",
    "    Perform the Fama-French three-factor regression and store the resulting data, residuals, and adjusted values in data frames\n",
    "    '''\n",
    "    results_list = []\n",
    "    residuals_dict = {}\n",
    "    fitted_values_dict = {}\n",
    "    # only numeric Regressor columns\n",
    "    X = df_regressor_fama.select_dtypes(include=['float64', 'int64'])\n",
    "    # Loop through the columns of log_excess_return\n",
    "    for column in log_excess_return.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        y = log_excess_return[column].astype(float)  # Convert to float if necessary\n",
    "        # Combine dependent variable and regressors, removing NaN rows\n",
    "        regression_data = pd.concat([y, X], axis=1).dropna()\n",
    "        y_clean = regression_data.iloc[:, 0]\n",
    "        X_clean = sm.add_constant(regression_data.iloc[:, 1:])\n",
    "        model = sm.OLS(y_clean, X_clean)\n",
    "        results = model.fit()\n",
    "        # Temporarily saving regression results \n",
    "        result_dict = {\n",
    "            'Fund': column, \n",
    "            'Alpha': results.params[0], \n",
    "            'P-Values Alpha': results.pvalues[0], \n",
    "            'R-Squared': results.rsquared, \n",
    "            'Model P-Value': results.f_pvalue, \n",
    "            'Confidence Interval Alpha': results.conf_int().iloc[0].tolist()\n",
    "        }\n",
    "        # Adding Betas, p-values and confidence intervals\n",
    "        for i, regressor in enumerate(X.columns):\n",
    "            result_dict[f'Beta {regressor}'] = results.params[i + 1]\n",
    "            result_dict[f'P-Value Beta {regressor}'] = results.pvalues[i + 1]\n",
    "            result_dict[f'Confidence Interval Beta {regressor}'] = results.conf_int().iloc[i + 1].tolist()\n",
    "        results_list.append(result_dict)\n",
    "        # Temporarily saving residuals and fitted values\n",
    "        residuals_dict[column] = pd.Series(results.resid).reindex(log_excess_return.index).tolist()\n",
    "        fitted_values_dict[column] = pd.Series(results.fittedvalues).reindex(log_excess_return.index).tolist()\n",
    "\n",
    "    # Converting results, residuals and fitted values to dataframes\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    residuals_df = pd.DataFrame(residuals_dict, index=log_excess_return.index)\n",
    "    fitted_values_df = pd.DataFrame(fitted_values_dict, index=log_excess_return.index)\n",
    "    # Saving to Excel\n",
    "    results_df.to_excel(writer, sheet_name='Fama Results', index=False)\n",
    "    residuals_df.to_excel(writer, sheet_name='Residuals', index=True)\n",
    "    fitted_values_df.to_excel(writer, sheet_name='Fitted Values', index=True)\n",
    "    return results_df, residuals_df, fitted_values_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f81a810-7419-4f3e-8167-c0004eaca6dd",
   "metadata": {},
   "source": [
    "#### Descriptive Analysis of the funds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "463b40cf-28db-46e0-af2e-b4beae6600f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_statistics(log_return, writer):\n",
    "    '''\n",
    "    Saves the descriptive statistics of the logarithmized excess returns in an Excel spreadsheet\n",
    "    '''\n",
    "    # Filter only numeric columns\n",
    "    numeric_df = log_return.select_dtypes(include=['float64', 'int64'])\n",
    "    # Calculate the descriptive statistics\n",
    "    descriptive_stats = numeric_df.describe().transpose()\n",
    "    # Calculate the kurtosis and skewness\n",
    "    descriptive_stats['Skewness'] = numeric_df.skew()\n",
    "    descriptive_stats['Excess-Kurtosis'] = numeric_df.kurt()\n",
    "    # Saving descriptive statistics in Excel\n",
    "    descriptive_stats.to_excel(writer, sheet_name='Descriptive Statistics', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06a86fb-1158-4bbd-b422-1dff9a066f91",
   "metadata": {},
   "source": [
    "### Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093f6eba-016c-4b28-90cf-692a490592f1",
   "metadata": {},
   "source": [
    "#### Check for Normal Distribution & Homoskedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9dbc3a2b-2efd-4891-b1f4-a4f3d2506c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_tests(residuals_df, fitted_values_df, regressor, excess_returns_df, output_dir, writer):\n",
    "    '''\n",
    "    Performs Breusch-Pagan, White, Shapiro-Wilk, and Jarque-Bera tests, and creates combined plots for each column in residuals_df.\n",
    "    '''\n",
    "    # Create empty DataFrames and lists for the results\n",
    "    results_bp_df = pd.DataFrame(columns=['Fund', 'LM stat', 'p-value', 'f-value', 'f p-value'])\n",
    "    results_white_df = pd.DataFrame(columns=['Fund', 'LM stat', 'p-value', 'f-stat', 'f p-value'])\n",
    "    shapiro_results = []\n",
    "    jarque_bera_results = []\n",
    "    # Loop through each column in residuals_df\n",
    "    for column in residuals_df.columns:\n",
    "        residuals = residuals_df[column].dropna()\n",
    "        matching_indices = residuals.index\n",
    "        # Ensure indices are sorted and are datetime objects\n",
    "        if not pd.api.types.is_datetime64_any_dtype(matching_indices):\n",
    "            try:\n",
    "                matching_indices = pd.to_datetime(matching_indices)\n",
    "            except Exception as e:\n",
    "                print(f'Error converting indices to datetime for column \"{column}\": {e}')\n",
    "                continue\n",
    "        residuals = residuals.sort_index()\n",
    "        matching_indices = residuals.index\n",
    "        # Ensure fitted_values_df, regressor, and excess_returns_df have matching indices\n",
    "        fitted_values = fitted_values_df[column].loc[matching_indices].sort_index()\n",
    "        excess_returns = excess_returns_df[column].loc[matching_indices].sort_index()\n",
    "        regressor_filtered = regressor.loc[matching_indices].sort_index()\n",
    "        # Add constant to regressors\n",
    "        exog_with_const = sm.add_constant(regressor_filtered)\n",
    "\n",
    "        # Perform Breusch-Pagan test\n",
    "        bp_test_result = het_breuschpagan(residuals, exog_with_const)\n",
    "        bp_new_row = pd.DataFrame({\n",
    "            'Fund': [column],\n",
    "            'LM stat': [bp_test_result[0]],\n",
    "            'p-value': [bp_test_result[1]],\n",
    "            'f-value': [bp_test_result[2]],\n",
    "            'f p-value': [bp_test_result[3]]\n",
    "        })\n",
    "        results_bp_df = pd.concat([results_bp_df, bp_new_row], ignore_index=True)\n",
    "\n",
    "        # Perform White test\n",
    "        white_test_result = het_white(residuals, exog_with_const)\n",
    "        white_new_row = pd.DataFrame({\n",
    "            'Fund': [column],\n",
    "            'LM stat': [white_test_result[0]],\n",
    "            'p-value': [white_test_result[1]],\n",
    "            'f-stat': [white_test_result[2]],\n",
    "            'f p-value': [white_test_result[3]]\n",
    "        })\n",
    "        results_white_df = pd.concat([results_white_df, white_new_row], ignore_index=True)\n",
    "\n",
    "        # Perform Shapiro-Wilk test\n",
    "        shapiro_test = stats.shapiro(residuals)\n",
    "        shapiro_results.append({\n",
    "            'Fund': column,\n",
    "            'Shapiro-Wilk Statistic': shapiro_test.statistic,\n",
    "            'p-value': shapiro_test.pvalue\n",
    "        })\n",
    "\n",
    "        # Perform Jarque-Bera test\n",
    "        jb_test = stats.jarque_bera(residuals)\n",
    "        skewness = stats.skew(residuals)\n",
    "        kurtosis = stats.kurtosis(residuals, fisher=False)  # Pearson's definition\n",
    "        jarque_bera_results.append({\n",
    "            'Fund': column,\n",
    "            'Jarque-Bera Statistic': jb_test.statistic,\n",
    "            'p-value': jb_test.pvalue,\n",
    "            'Skewness': skewness,\n",
    "            'Kurtosis': kurtosis\n",
    "        })\n",
    "\n",
    "        # Calculation of standardized residuals and fitted values\n",
    "        std_residuals = np.std(residuals, ddof=2)\n",
    "        std_fitted_values = np.std(fitted_values, ddof=1)\n",
    "        standardized_fitted_values = (fitted_values - np.mean(fitted_values)) / std_fitted_values\n",
    "        standardized_residuals = (residuals - np.mean(residuals)) / std_residuals\n",
    "\n",
    "        # Plot 1: Residuals vs. Fitted Values\n",
    "        fig, axs1 = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        axs1[0, 0].scatter(fitted_values, residuals, edgecolor='k', alpha=0.7)\n",
    "        axs1[0, 0].set_title(f'Residuals vs. Fitted Values for {column}')\n",
    "        axs1[0, 0].set_xlabel('Fitted Values')\n",
    "        axs1[0, 0].set_ylabel('Residuals')\n",
    "        axs1[0, 0].axhline(0, color='red', linestyle='-', linewidth=1)\n",
    "        \n",
    "        # Plot 2: Residuals vs. Fitted Values\n",
    "        axs1[0, 1].scatter(standardized_fitted_values, standardized_residuals, edgecolor='k', alpha=0.7)\n",
    "        axs1[0, 1].set_title(f'Stand. Residuals vs. Stand. Fitted Values für {column}')\n",
    "        axs1[0, 1].set_xlabel('Standardized Fitted Values')\n",
    "        axs1[0, 1].set_ylabel('Standardized Residuals')\n",
    "        axs1[0, 1].axhline(0, color='red', linestyle='-', linewidth=1)\n",
    "\n",
    "        # Plot 3: QQ Plot\n",
    "        sm.qqplot(residuals, line='s', ax=axs1[1, 0])\n",
    "        axs1[1, 0].set_title(f'QQ-Plot of Residuals for {column}')\n",
    "\n",
    "        # Plot 4: Histogram\n",
    "        axs1[1, 1].hist(residuals, bins=30, edgecolor='k', alpha=0.7)\n",
    "        axs1[1, 1].set_title(f'Histogram of Residuals for {column}')\n",
    "        axs1[1, 1].set_xlabel('Residuals')\n",
    "        axs1[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "        # Saving Plots\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_dir}/residual_tests_{column}.png\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    # After the loop, save results to Excel\n",
    "    shapiro_df = pd.DataFrame(shapiro_results)\n",
    "    shapiro_df.to_excel(writer, sheet_name='Shapiro-Wilk Test', index=False)\n",
    "    jb_df = pd.DataFrame(jarque_bera_results)\n",
    "    jb_df.to_excel(writer, sheet_name='Jarque-Bera Test', index=False)\n",
    "    results_bp_df.to_excel(writer, sheet_name='Breusch-Pagan Test', index=False)\n",
    "    results_white_df.to_excel(writer, sheet_name='White Test', index=False)\n",
    "    return results_bp_df, results_white_df, shapiro_df, jb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05437a0-cd86-4274-986f-04e1defa1ced",
   "metadata": {},
   "source": [
    "#### Check for Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0874eb6b-3a30-4f49-bcbb-f8211d49bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def durbin_watson_capm(residuals_df, writer):\n",
    "    '''\n",
    "    Performs the Durbin-Watson test and saves the results in an Excel file.\n",
    "    '''\n",
    "    # Calculate Durbin-Watson statistics for each fund's residuals\n",
    "    dw_results = {column: durbin_watson(residuals_df[column].dropna()) for column in residuals_df.columns}\n",
    "    # Convert the results into a DataFrame\n",
    "    dw_df = pd.DataFrame(list(dw_results.items()), columns=['Fund', 'Durbin-Watson Statistic'])\n",
    "    # Save the Durbin-Watson test results to an Excel file\n",
    "    dw_df.to_excel(writer, sheet_name='Durbin-Watson Test', index=False)\n",
    "    return dw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9d5a31-2916-4f97-b950-0eb7fddbb3c1",
   "metadata": {},
   "source": [
    "#### Check for Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f17b6fb9-2ca2-4d80-ad02-3654a6e30216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor_variation(df_regressor_capm, writer):\n",
    "    '''\n",
    "    Checks the variation of the independent variables (regressors) and saves the results in an Excel file\n",
    "    '''\n",
    "    std_regressors = df_regressor_capm.std()\n",
    "    if isinstance(std_regressors, pd.Series):\n",
    "        std_regressors_df = std_regressors.to_frame(name='Standard Deviation')\n",
    "    else:\n",
    "        std_regressors_df = pd.DataFrame({'Standard Deviation': [std_regressors]})\n",
    "    std_regressors_df.to_excel(writer, sheet_name='Regressor Variation', index=True)\n",
    "\n",
    "def regressor_variation_fama(df_regressor_fama, writer):\n",
    "    '''\n",
    "    Checks the variation of the independent variables (regressors) and saves the results in an Excel file\n",
    "    '''\n",
    "    # Calculate the standard deviation of the regressors\n",
    "    std_regressors = df_regressor_fama.std()\n",
    "    # Convert the Series to a DataFrame\n",
    "    std_regressors_df = std_regressors.to_frame(name='Standard Deviation')\n",
    "    # Save the standard deviation data to an Excel file\n",
    "    std_regressors_df.to_excel(writer, sheet_name='Fama Regressor Variation', index=True)\n",
    "    return std_regressors_df\n",
    "\n",
    "def vif_fama(df_regressor_fama):\n",
    "    '''\n",
    "    Calculates the Variance Inflation Factor (VIF) for each variable in the Fama-French model's regressor data.\n",
    "    '''\n",
    "    # Add a constant to the DataFrame for the intercept\n",
    "    df_with_constant = sm.add_constant(df_regressor_fama)\n",
    "    # Create a DataFrame to hold VIF results\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data['Variable'] = df_with_constant.columns\n",
    "    vif_data['VIF'] = [variance_inflation_factor(df_with_constant.values, i) for i in range(df_with_constant.shape[1])]\n",
    "    return vif_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d972ed8-f6fe-453a-90ae-561dda88a75a",
   "metadata": {},
   "source": [
    "### Beginning the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0158c0d3-3908-4676-b7f4-839b27f739cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the calculate_log_returns function on the closing prices\n",
    "df_raw_log_etf_returns = calculate_log_returns(df_closing_etf)\n",
    "df_raw_log_mutual_returns = calculate_log_returns(df_closing_mutual)\n",
    "df1 = pd.DataFrame(df_raw_log_etf_returns)\n",
    "df2 = pd.DataFrame(df_raw_log_mutual_returns)\n",
    "# Removing the first line (01.01.2024)\n",
    "df1 = df1[1:]\n",
    "df2 = df2[1:]\n",
    "\n",
    "# Applying the replace_nans_and_zeros_with_mean function\n",
    "for col in df1.columns:\n",
    "    if col != 'Date':  # Ignoring the date column\n",
    "        df1[col] = replace_nans_and_zeros_with_mean(df1[col].copy())\n",
    "for col in df2.columns:\n",
    "    if col != 'Date':  # Ignoring the date column\n",
    "        df2[col] = replace_nans_and_zeros_with_mean(df2[col].copy())\n",
    "\n",
    "# Ensuring df1 and df_riskfree have the same index\n",
    "df1.set_index('Date', inplace=True)\n",
    "df_riskfree.set_index('Dates', inplace=True)\n",
    "\n",
    "# Align df_riskfree with df1\n",
    "df_riskfree_aligned = df_riskfree.reindex(df1.index)\n",
    "\n",
    "# Subtract risk-free rate only where df is non-zero\n",
    "df_log_excess_return_etf = df1.where(df1 == 0, df1.subtract(df_riskfree_aligned['ln riskfree'], axis=0))\n",
    "\n",
    "# For df2\n",
    "df2.set_index('Date', inplace=True)\n",
    "df_log_excess_return_mutual = df2.where(df2 == 0, df2.subtract(df_riskfree_aligned['ln riskfree'], axis=0))\n",
    "df1.replace(0.00, np.nan, inplace=True)\n",
    "df_log_excess_return_etf.replace(0.00, np.nan, inplace=True)\n",
    "df2.replace(0.00, np.nan, inplace=True)\n",
    "df_log_excess_return_mutual.replace(0.00, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fab58ba-374a-4502-b17a-88517f038ad6",
   "metadata": {},
   "source": [
    "#### CAPM Regression for ETFs and Mutual Funds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d55ae6-3a52-459a-a17a-10b42e87b737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAPM Regression for ETFs\n",
    "output_file_path = r'C:\\Users\\...\\CAPM_Results_ETF.xlsx'\n",
    "output_file_path_pictures = r'C:\\Users\\...\\Pictures\\CAPM_ETF'\n",
    "\n",
    "with pd.ExcelWriter(output_file_path, engine='openpyxl') as writer:\n",
    "    results_df, residuals_df, fitted_values_df = regression_capm(df_log_excess_return_etf, df_regressor_capm ,writer)\n",
    "    descriptive_statistics(df1, writer)\n",
    "    combined_tests(residuals_df, fitted_values_df, df_regressor_capm, df_log_excess_return_etf, output_file_path_pictures, writer)\n",
    "    dw_df = durbin_watson_capm(residuals_df, writer)\n",
    "    df_regressor_capm.to_excel(writer, sheet_name='Regressor')\n",
    "    regressor_variation(df_regressor_capm['ln excess'], writer)\n",
    "    df1.to_excel(writer, sheet_name='Log Returns ETF')\n",
    "    df_log_excess_return_etf.to_excel(writer, sheet_name='Log Excess Returns ETF')\n",
    "\n",
    "# CAPM Regression for Mutual Funds\n",
    "output_file_path = r'C:\\Users\\...\\CAPM_Results_Mutual.xlsx'\n",
    "output_file_path_pictures = r'C:\\Users\\...\\Pictures\\CAPM_Mutual'\n",
    "\n",
    "with pd.ExcelWriter(output_file_path, engine='openpyxl') as writer:\n",
    "    results_df, residuals_df, fitted_values_df = regression_capm(df_log_excess_return_mutual, df_regressor_capm ,writer)\n",
    "    descriptive_statistics(df2, writer)\n",
    "    combined_tests(residuals_df, fitted_values_df, df_regressor_capm, df_log_excess_return_mutual, output_file_path_pictures, writer)\n",
    "    dw_df = durbin_watson_capm(residuals_df, writer)\n",
    "    df_regressor_capm.to_excel(writer, sheet_name='Regressor')\n",
    "    regressor_variation(df_regressor_capm['ln excess'], writer)\n",
    "    df2.to_excel(writer, sheet_name='Log Returns ETF')\n",
    "    df_log_excess_return_mutual.to_excel(writer, sheet_name='Log Excess Returns ETF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437c022c-74eb-4dde-99f4-d5813a7ba2ab",
   "metadata": {},
   "source": [
    "#### Fama Regression for ETFs and Mutual Funds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aac9262-f57f-4f05-889d-e96c69551dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAMA Regression for ETFs\n",
    "output_file_path = r'C:\\Users\\...\\FAMA_Results_ETF.xlsx'\n",
    "output_file_path_pictures = r'C:\\Users\\...\\Pictures\\FAMA_ETF'\n",
    "\n",
    "with pd.ExcelWriter(output_file_path, engine='openpyxl') as writer:\n",
    "    results_df, residuals_df, fitted_values_df = regression_fama(df_log_excess_return_etf, df_regressor_fama, writer=writer)\n",
    "    combined_tests(residuals_df, fitted_values_df, df_regressor_fama, df_log_excess_return_etf, output_file_path_pictures, writer)\n",
    "    dw_df = durbin_watson_capm(residuals_df, writer)\n",
    "    vif_df = vif_fama(df_regressor_fama)\n",
    "    vif_df.to_excel(writer, sheet_name='VIF Results', index=False)\n",
    "    df_regressor_fama.to_excel(writer, sheet_name='Regressor') \n",
    "    regressor_variation_fama(df_regressor_fama, writer)\n",
    "\n",
    "# FAMA Regression for Mutual Funds\n",
    "output_file_path = r'C:\\Users\\...\\FAMA_Results_Mutual.xlsx'\n",
    "output_file_path_pictures = r'C:\\Users\\...\\Pictures\\FAMA_Mutual'\n",
    "\n",
    "with pd.ExcelWriter(output_file_path, engine='openpyxl') as writer:\n",
    "    results_df, residuals_df, fitted_values_df = regression_fama(df_log_excess_return_mutual, df_regressor_fama, writer=writer)\n",
    "    descriptive_statistics(df2, writer)\n",
    "    combined_tests(residuals_df, fitted_values_df, df_regressor_fama, df_log_excess_return_mutual, output_file_path_pictures, writer)\n",
    "    dw_df = durbin_watson_capm(residuals_df, writer)\n",
    "    vif_df = vif_fama(df_regressor_fama)\n",
    "    vif_df.to_excel(writer, sheet_name='VIF Results', index=False)\n",
    "    df_regressor_fama.to_excel(writer, sheet_name='Regressor') \n",
    "    regressor_variation_fama(df_regressor_fama, writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
